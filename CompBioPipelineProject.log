```python
# Importing necessary libraries and setting up email for Entrez
import os
import Bio
from Bio import Entrez

Entrez.email = "emaley@luc.edu"

# Retrieving HCMV genome fasta from NCBI
handle = Entrez.efetch(db="nucleotide", id='NC_006273.2', rettype='fasta')
fasta = handle.read()
handle.close()

# Writing HCMV genome fasta to file and building index for Bowtie2
with open('HCMV.fasta', 'w') as f:
  f.write(fasta)

os.system('bowtie2-build HCMV.fasta HCMV')

# Aligning reads to HCMV genome using Bowtie2
os.system('bowtie2 --quiet -x HCMV -1 SRR5660030_1.fastq -2 SRR5660030_2.fastq -S HCMV30mapped.sam')
os.system('bowtie2 --quiet -x HCMV -1 SRR5660033_1.fastq -2 SRR5660033_2.fastq -S HCMV33mapped.sam')
os.system('bowtie2 --quiet -x HCMV -1 SRR5660044_1.fastq -2 SRR5660044_2.fastq -S HCMV44mapped.sam')
os.system('bowtie2 --quiet -x HCMV -1 SRR5660045_1.fastq -2 SRR5660045_2.fastq -S HCMV45mapped.sam')
# Getting initial read counts for each sample
initial_counts = {}
samples_list = ['SRR5660030', 'SRR5660033', 'SRR5660044', 'SRR5660045']
for s in samples_list:
   with open(f'{s}_1.fastq') as file1:
       initial_counts[s] = sum([1 for line in file1]) / 4
   print(f'{s} has {initial_counts[s]:,} read pairs before filtering')

# Filtering out non-mapped reads and writing mapped reads to new fastq files
for s in samples_list:
   output_sam = f'{s}_mapped.sam'
   os.system(f'bowtie2 --quiet -x HCMV -1 {s}_1.fastq -2 {s}_2.fastq -S {output_sam}')

   post_filter_counts = 0
   with open(output_sam) as samfile, open(f'{s}_HCMV.fastq', 'w') as fastqfile:
       for line in samfile:
           if line.startswith('@'):
               continue
           parts = line.split('\t')
           flag_val = int(parts[1])

           if flag_val & 4 == 0:
               post_filter_counts += 1
               qname_val = parts[0]
               seq_val = parts[9]
               qual_val = parts[10]
               fastqfile.write(f"@{qname_val}\n{seq_val}\n+\n{qual_val}\n")

   # Writing filtered read counts to a log file
   with open('log.txt', 'a') as logfile:
       logfile.write(f'{s} has {initial_counts[s]:,} read pairs before filtering and {post_filter_counts:,} read pairs after filtering.\n')
```
```python
with open("blast_result.xml", "r") as result_handle:
    blast_records = list(NCBIXML.parse(result_handle))

# Open a new file in write mode to store the top 10 matches and write the header
with open("top_10_matches.txt", "w") as log_file:
    log_file.write("sacc\tpident\tlength\tqstart\tqend\tsstart\tsend\tbitscore\tevalue\ts
title\n")

    # Loop through each Blast record
    for record in blast_records:
        
        # Loop through the top 10 alignments for each record
        for alignment in record.alignments[:10]:
            # Extract the first HSP for each alignment
            hsp = alignment.hsps[0]  

            # Format the output line with the required fields and write it to the log file
            output_line = f"{alignment.accession}\t{hsp.identities * 100 / hsp.align_length:.2f}\t{hsp.align_length}\t{hsp.query_start}\t{hsp.query_end}\t{hsp.sbjct_start}\t{hsp.sbjct_end}\t{hsp.bits}\t{hsp.expect}\t{alignment.title}\n"
            log_file.write(output_line)
```
